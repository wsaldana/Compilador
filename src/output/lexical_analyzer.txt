"""
This file is autogenerated
"""

from src.afn import Thompson
import argparse

# Inputs
parser = argparse.ArgumentParser(description='Generated lexical analyzer')
parser.add_argument('filename', type=open, help='File to read and tokenize')
args = parser.parse_args()
print(args)

# Internal variables
postfixs =
alphabets =

# Create AFNs
anfs = {}
for token in postfixs.keys():
    thompson = Thompson(postfixs[token], alphabets[token])
    thompson.construct()
    anfs[token] = thompson


def tokenize(queue):
    word = []
    _token = list(anfs.keys())[0]
    while len(queue) > 0:
        match = False
        word.append(queue.pop(0))
        string = ''.join(word)
        for token, afn in anfs.items():
            if afn.simulate(string) == "Si":
                _token = token
                match = True
        if (not match) or len(queue) == 0:
            if len(word) == 1:
                print("UNDEFINED SYMBOL ", word.pop())
                break
            if len(queue) != 0:
                queue.insert(0, word.pop())
            string = ''.join(word)
            word = []
            print(f"<{string}, {_token}>")
            # token = _token


# Read file
with open(args.filename.name) as file:
    for line in file:
        queue = list(line)
        tokenize(queue)
